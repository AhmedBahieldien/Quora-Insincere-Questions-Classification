{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom torch import nn\nfrom torch import optim\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nfrom torchvision import datasets, transforms, models\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\nimport os\nfrom tqdm import tqdm\nimport math\nfrom zipfile import ZipFile\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":2,"outputs":[{"output_type":"stream","text":"/kaggle/input/quora-insincere-questions-classification/sample_submission.csv\n/kaggle/input/quora-insincere-questions-classification/embeddings.zip\n/kaggle/input/quora-insincere-questions-classification/test.csv\n/kaggle/input/quora-insincere-questions-classification/train.csv\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_set = pd.read_csv(\"/kaggle/input/quora-insincere-questions-classification/train.csv\")\ntrain_set, test_set = train_test_split(train_set, test_size=0.1)\nprint(len(train_set))\nprint(len(test_set))\ntrain_set.head()","execution_count":3,"outputs":[{"output_type":"stream","text":"1175509\n130613\n","name":"stdout"},{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"                         qid  \\\n444135  5706141e18a912aeccba   \n796936  9c2a6938781d7d123281   \n763343  958cdb9a7a5326fc4bb5   \n584637  7289b6ba075ca6468614   \n208082  28b33d319557c4c6a7e7   \n\n                                            question_text  target  \n444135  Has todays' technology made us impersonal and ...       0  \n796936  What is the effect of mobile computing on the ...       0  \n763343                  How is Kairos related to writing?       0  \n584637  What happened after Harry Potter and Ginny Wea...       0  \n208082        Why do most girls hate boys who watch porn?       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>qid</th>\n      <th>question_text</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>444135</th>\n      <td>5706141e18a912aeccba</td>\n      <td>Has todays' technology made us impersonal and ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>796936</th>\n      <td>9c2a6938781d7d123281</td>\n      <td>What is the effect of mobile computing on the ...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>763343</th>\n      <td>958cdb9a7a5326fc4bb5</td>\n      <td>How is Kairos related to writing?</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>584637</th>\n      <td>7289b6ba075ca6468614</td>\n      <td>What happened after Harry Potter and Ginny Wea...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>208082</th>\n      <td>28b33d319557c4c6a7e7</td>\n      <td>Why do most girls hate boys who watch porn?</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"#preproccesing data pipeline \nimport nltk  #Natural Language Toolkit\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nnltk.download('stopwords')\n\ndef to_lower(question_text):\n    return question_text.lower()\n    \ndef remove_numbers(question_text):\n    return ''.join([c for c in question_text if not c.isdigit()])\n\ndef remove_punctuation(question_text):\n    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n    filtered_question_text_tokenized =tokenizer.tokenize(question_text)\n    return filtered_question_text_tokenized\n\ndef remove_stopwords(question_text):\n    \n    filtered_question_text = [word for word in question_text if not word in stopwords.words()]\n    return filtered_question_text\n\ndef preproccesing(question_text):\n    question_text = to_lower(question_text)\n    question_text = remove_numbers(question_text)\n    question_text = remove_punctuation(question_text)\n    question_text = remove_stopwords(question_text)\n    question_text = ' '.join(question_text)\n    return question_text\n\ntest = 'a testing for the question.'\npreproccesing(test)","execution_count":4,"outputs":[{"output_type":"stream","text":"[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n","name":"stdout"},{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"'testing question'"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"filtered_training_set = []\nprint(train_set['question_text'].shape)\nfor text in train_set['question_text'][:10000]:\n    filtered_training_set.append(preproccesing(text))\n#Analysis\ntrain_set_numpy = np.array(filtered_training_set)\nmax=0\nfor i in train_set_numpy:\n    if max < len(i.split()):\n        max=len(i.split())\nprint(max)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with ZipFile('/kaggle/input/quora-insincere-questions-classification/embeddings.zip', 'r') as zipObj:\n   # Get a list of all archived file names from the zip\n   listOfFileNames = zipObj.namelist()\n   # Iterate over the file names\n   zipObj.extract('GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin')","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"filepath = \"GoogleNews-vectors-negative300/GoogleNews-vectors-negative300.bin\"\nembeddings_index = {}\nfrom gensim.models import KeyedVectors\nwv_from_bin = KeyedVectors.load_word2vec_format(filepath, binary=True) \nfor word, vector in zip(wv_from_bin.vocab, wv_from_bin.vectors):\n    coefs = np.asarray(vector, dtype='float32')\n    embeddings_index[word] = coefs\n    \n","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def word_embedding(text):\n#word2vec-GoogleNews-vectors\n#This repository hosts the word2vec pre-trained Google News corpus (3 billion running words)\n#word vector model (3 million 300-dimension English word vectors).\n    embeddings_dim = 300\n    max_num_word = 30\n\n    zero_embeddings = np.zeros(embeddings_dim)\n    \n    #text = preproccesing(text)\n    #max num of words in  text is 35 \n    text = text.split()[:max_num_word]\n    embeddings = [embeddings_index.get(word, zero_embeddings) for word in text]\n    #print(len(embeddings[0]))\n    #print([zero_embeddings] * (35 - len(embeddings)))\n    embeddings = embeddings + [zero_embeddings] * (max_num_word - len(embeddings))\n    embeddings = np.array(embeddings)\n    #print(embeddings.shape)\n    return embeddings","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nepochs=10\nsteps_per_epoch=500\nlearning_rate=0.1","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def batch_generation(train_set):\n    num_batches = math.ceil(len(train_set) / batch_size)\n    while True: \n        #return random sample \n        train_set = train_set.sample(frac=1.)  \n        for i in range(num_batches):\n            batch_texts = train_set.iloc[i*batch_size:(i+1)*batch_size,1]\n            batch_texts_array = np.array([word_embedding(text) for text in batch_texts])\n            batch_targets = np.array(train_set[\"target\"][i*batch_size:(i+1)*batch_size])\n            yield batch_texts_array , batch_targets","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"test_x = np.array([word_embedding(data) for data in test_set[\"question_text\"][:2000]])\ntest_y = np.array(test_set[\"target\"][:2000])\nprint(test_x.shape)","execution_count":10,"outputs":[{"output_type":"stream","text":"(2000, 30, 300)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow import keras\n\nfrom keras.models import Sequential\n\nfrom keras.layers import LSTM, Dense, Bidirectional,Dropout,Embedding\n\nmodel = Sequential()\n\n#model = Embedding(max_num_word, embeddings_dim, weights=[embedding_matrix],trainable=False)\n\nmodel.add(Bidirectional(LSTM(64, return_sequences=True),input_shape=(30, 300)))\n\nmodel.add(Dropout(0.2))   \n\nmodel.add(Dense(1, activation=\"sigmoid\"))","execution_count":11,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"opt = keras.optimizers.Adam(learning_rate=learning_rate)\n\nmodel.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#.fit is used when the entire training dataset can fit into the memory and no data augmentation is applied.\n#.fit_generator is used when either we have a huge dataset to fit into our memory or when data augmentation needs to be applied.\ntrain_loaders = batch_generation(train_set)\nmodel.fit_generator(train_loaders, epochs=epochs,\n                    steps_per_epoch=steps_per_epoch,\n                    validation_data=(test_x, test_y),\n                    verbose=True)    #show trainning progress","execution_count":13,"outputs":[{"output_type":"stream","text":"Epoch 1/10\n500/500 [==============================] - 22s 43ms/step - loss: 0.1964 - accuracy: 0.9339 - val_loss: 0.1504 - val_accuracy: 0.9438\nEpoch 2/10\n500/500 [==============================] - 21s 41ms/step - loss: 0.1700 - accuracy: 0.9401 - val_loss: 0.1605 - val_accuracy: 0.9441\nEpoch 3/10\n500/500 [==============================] - 21s 43ms/step - loss: 0.2182 - accuracy: 0.9378 - val_loss: 0.2170 - val_accuracy: 0.9416\nEpoch 4/10\n500/500 [==============================] - 21s 42ms/step - loss: 0.2209 - accuracy: 0.9396 - val_loss: 0.2140 - val_accuracy: 0.9416\nEpoch 5/10\n500/500 [==============================] - 20s 41ms/step - loss: 0.2369 - accuracy: 0.9371 - val_loss: 0.2226 - val_accuracy: 0.9415\nEpoch 6/10\n500/500 [==============================] - 22s 43ms/step - loss: 0.2472 - accuracy: 0.9358 - val_loss: 0.2292 - val_accuracy: 0.9415\nEpoch 7/10\n500/500 [==============================] - 20s 41ms/step - loss: 0.2419 - accuracy: 0.9380 - val_loss: 0.2263 - val_accuracy: 0.9415\nEpoch 8/10\n500/500 [==============================] - 20s 41ms/step - loss: 0.2340 - accuracy: 0.9386 - val_loss: 0.2125 - val_accuracy: 0.9414\nEpoch 9/10\n500/500 [==============================] - 21s 42ms/step - loss: 0.2381 - accuracy: 0.9389 - val_loss: 0.2677 - val_accuracy: 0.9415\nEpoch 10/10\n500/500 [==============================] - 20s 40ms/step - loss: 0.2412 - accuracy: 0.9370 - val_loss: 0.2198 - val_accuracy: 0.9415\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7f45f7d62b10>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}